library(tidyverse) # обработка данных, графики...
library(vcd) # мозаичные графики для качественных переменных
library(skimr) # описательные статистики
library(rio) # импорт фантастического количества форматов данных
library(ggalluvial) # потоковые ???? графики для качественных переменных
library(nycflights13) # набор данных о вылетах из Нью-Йорка
library(corrplot) # визуализация корреляций
library(reshape2) # длинные и широкие таблицы
install.packages("feather")
library(tidyverse) # обработка данных, графики...
library(vcd) # мозаичные графики для качественных переменных
library(skimr) # описательные статистики
library(rio) # импорт фантастического количества форматов данных
library(ggalluvial) # потоковые ???? графики для качественных переменных
library(nycflights13) # набор данных о вылетах из Нью-Йорка
library(corrplot) # визуализация корреляций
library(reshape2) # длинные и широкие таблицы
table(diamonds$color)
levels(diamonds$color)
diamonds2 <- mutate(diamonds, color = fct_collapse(color, United = c('D', 'E', 'F')))
table(diamonds2$color)
diamonds3 <- mutate(diamonds, cut = fct_collapse(`Premium`, `Ideal`))
table(diamonds3$cut)
diamonds2 <- mutate(diamonds, color = fct_collapse(color, United = c('D', 'E', 'F')))
table(diamonds2$color)
diamonds3 <- mutate(diamonds, cut = fct_collapse(cut, best=c(`Premium`, `Ideal`)))
table(diamonds3$cut)
diamonds3 <- mutate(diamonds,
cut = fct_collapse(cut, best=c(`Premium`,`Ideal`)))
table(diamonds3$cut)
diamonds3 <- mutate(diamonds,
cut = fct_collapse(cut, best=c(`Premium`,`Ideal`)))
table(diamonds3$cut)
table(diamonds$color)
levels(diamonds$color)
diamonds2 <- mutate(diamonds, color = fct_collapse(color, United = c('D', 'E', 'F')))
table(diamonds2$color)
diamonds3 <- mutate(diamonds,
cut = fct_collapse(cut, Best=c(`Premium`,`Ideal`)))
table(diamonds3$cut)
diamonds3 <- mutate(diamonds,
cut = fct_collapse(cut, Best=c('Premium', "Ideal")))
table(diamonds3$cut)
diamonds2 <- mutate(diamonds, color = fct_collapse(color, United = c('D', 'E', 'F')))
table(diamonds2$color)
diamonds3 <- mutate(diamonds,
cut = fct_collapse(cut, Best = c('Premium', "Ideal")))
table(diamonds3$cut)
library(tidyverse) # обработка данных, графики...
library(skimr) # описательные статистики
library(rio) # импорт фантастического количества форматов данных
library(broom) # метла превращает результаты оценивания моделей в таблички
library(GGally) # больше готовых графиков
library(sjPlot) # ещё больше графиков
library(lmtest) # диагностика линейных моделей
library(Ecdat) # много-много разных наборов данных
library(sjstats) # удобные мелкие функции для работы с моделями
library(sandwich) # оценка Var для гетероскедастичности
library(AER) # работа с инструментальными переменными
install.packages("MASS")
install.packages("car")
library(tidyverse) # обработка данных, графики...
library(skimr) # описательные статистики
library(rio) # импорт фантастического количества форматов данных
library(broom) # метла превращает результаты оценивания моделей в таблички
library(GGally) # больше готовых графиков
library(sjPlot) # ещё больше графиков
library(lmtest) # диагностика линейных моделей
library(Ecdat) # много-много разных наборов данных
library(sjstats) # удобные мелкие функции для работы с моделями
library(sandwich) # оценка Var для гетероскедастичности
library(AER) # работа с инструментальными переменными
install.packages("rlang")
install.packages("data.table")
library(tidyverse) # обработка данных, графики...
library(skimr) # описательные статистики
library(rio) # импорт фантастического количества форматов данных
library(broom) # метла превращает результаты оценивания моделей в таблички
library(GGally) # больше готовых графиков
library(sjPlot) # ещё больше графиков
library(lmtest) # диагностика линейных моделей
library(Ecdat) # много-много разных наборов данных
library(sjstats) # удобные мелкие функции для работы с моделями
library(sandwich) # оценка Var для гетероскедастичности
library(AER) # работа с инструментальными переменными
install.packages(c("stringi", "openxlsx"))
library(tidyverse) # обработка данных, графики...
library(skimr) # описательные статистики
library(rio) # импорт фантастического количества форматов данных
library(broom) # метла превращает результаты оценивания моделей в таблички
library(GGally) # больше готовых графиков
library(sjPlot) # ещё больше графиков
library(lmtest) # диагностика линейных моделей
library(Ecdat) # много-много разных наборов данных
library(sjstats) # удобные мелкие функции для работы с моделями
library(sandwich) # оценка Var для гетероскедастичности
library(AER) # работа с инструментальными переменными
install.packages("mvtnorm")
g1 <- fviz_nbclust(protein_no_country, kmeans, method = 'wss') +
labs(subtitle = 'Elbow method')
g1
g2 <- fviz_nbclust(protein_no_country, kmeans, method = 'silhouette') +
labs(subtitle = 'Silhouette method')
g2
g3 <- fviz_nbclust(protein_no_country, kmeans, method = 'gap_stat') +
labs(subtitle = 'Gap statistic method')
g3
(g1 + g2) / g3
g1 + g2 + g3
g1 + (g2 / g3)
# p1 <- fviz_nbclust(___, kmeans, method = 'wss') +
#  labs(subtitle = 'Elbow method')
# p2 <- fviz_nbclust(___, ___, method = 'silhouette') +
#  labs(subtitle = 'Silhouette method')
# p3 <- fviz_nbclust(___, ___, method = 'gap_stat') +
#  labs(subtitle = 'Gap statistic method')
# (___ + ___) / ___
# p1 <- fviz_nbclust(___, kmeans, method = 'wss') +
#  labs(subtitle = 'Elbow method')
# p2 <- fviz_nbclust(___, ___, method = 'silhouette') +
#  labs(subtitle = 'Silhouette method')
# p3 <- fviz_nbclust(___, ___, method = 'gap_stat') +
#  labs(subtitle = 'Gap statistic method')
# (___ + ___) / ___
g1 <- fviz_nbclust(protein_no_country, kmeans, method = 'wss') +
labs(subtitle = 'Elbow method')
g1
devtools::install_github('thomasp85/patchwork')
library(tidyverse) # обработка данных, графики...
library(skimr)# описательные статистики
library(rio) # импорт фантастического количества форматов данных
library(cluster) # кластерный анализ
library(factoextra) # визуализации kmeans, pca,
library(dendextend) # визуализация дендрограмм
library(corrplot) # визуализация корреляций
library(broom) # метла превращает результаты оценивания моделей в таблички
library(naniar) # визуализация пропущенных значений
library(visdat) # визуализация пропущенных значений
library(patchwork) # удобное расположение графиков рядом
library(nycflights13) # baby - большие данные
b <- 11:15
# Chunk 1: setup
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)
# Chunk 2
library(tidyverse) # обработка данных, графики...
library(skimr) # описательные статистики
library(rio) # импорт фантастического количества форматов данных
library(ISLR) # ещё данные
library(caret) # пакет для подбора параметров разных моделей
library(FFTrees) # быстрые деревья
library(margins) # для подсчёта предельных эффектов
library(rpart.plot) # для картинок деревьев
library(plotROC) # визуализация ROC-кривой
library(ggeffects) # графики для предельных эффектов
library(MLmetrics) # метрики качества
library(ranger) # случайный лес
library(factoextra) # графики для кластеризации и pca
library(elasticnet) # LASSO
library(latex2exp) # формулы в подписях к графику
library(distances) # расчет различных расстояний
# Chunk 3
educ <- import('data/xAPI-Edu-Data.csv')
skim(educ)
# Chunk 4
educ_logit <- mutate(educ, y = fct_collapse(Class, H = c('M', 'H'))) %>%
select(-Class)
educ_fct <- mutate_if(educ_logit, is.character, factor)
# Chunk 5
educ_fct_rel <- mutate(educ_fct, y = fct_relevel(y, 'L'))
# Chunk 6
set.seed(777)
train_rows <- createDataPartition(educ_fct$y, p = 0.8, list = FALSE)
educ_train <- educ_fct[train_rows, ]
educ_test <- educ_fct[-train_rows, ]
def <- Default
skim(def)
glimpse(Default)
set.seed(13)
train_rows <- createDataPartition(def$default, p = 0.7, list = FALSE)
def_train <- def[train_rows, ]
def_test <- def[-train_rows, ]
def_lmodel <- train(data = def_train, default ~ student + balance +income, family = binomial(link = 'logit'), method = 'glm')
summary(def_lmodel)
def_pred <- predict(def_lmodel, newdata = def_test)
head(def_pred)
def_prob <- predict(def_lmodel, newdata = def_test, type = 'prob')
head(def_prob)
confusionMatrix(data = def_pred, reference = def_test$default)
educ_test_set <- data.frame(H = educ_prob$H,
L = educ_prob$L,
pred = educ_pred,
obs = educ_test$y)
glimpse(educ_test_set)
levs <- levels(educ_test_set$obs)
twoClassSummary(educ_test_set, lev = levs) # don't work with tibble
prSummary(educ_test_set, lev = levs) # нужен пакет MLmetrics
educ_pred <- predict(educ_lmodel, newdata = educ_test)
head(educ_pred)
educ_prob <- predict(educ_lmodel, newdata = educ_test, type = 'prob')
head(educ_prob)
library(tidyverse) # обработка данных, графики...
library(skimr) # описательные статистики
library(rio) # импорт фантастического количества форматов данных
library(ISLR) # ещё данные
library(caret) # пакет для подбора параметров разных моделей
library(FFTrees) # быстрые деревья
library(margins) # для подсчёта предельных эффектов
library(rpart.plot) # для картинок деревьев
library(plotROC) # визуализация ROC-кривой
library(ggeffects) # графики для предельных эффектов
library(MLmetrics) # метрики качества
library(ranger) # случайный лес
library(factoextra) # графики для кластеризации и pca
library(elasticnet) # LASSO
library(latex2exp) # формулы в подписях к графику
library(distances) # расчет различных расстояний
educ <- import('data/xAPI-Edu-Data.csv')
setwd("D:/R_teaching/r_course")
educ <- import('data/xAPI-Edu-Data.csv')
skim(educ)
educ_logit <- mutate(educ, y = fct_collapse(Class, H = c('M', 'H'))) %>%
select(-Class)
educ_fct <- mutate_if(educ_logit, is.character, factor)
educ_fct_rel <- mutate(educ_fct, y = fct_relevel(y, 'L'))
set.seed(777)
train_rows <- createDataPartition(educ_fct$y, p = 0.8, list = FALSE)
educ_train <- educ_fct[train_rows, ]
educ_test <- educ_fct[-train_rows, ]
educ_lmodel <- train(data = educ_train,
y ~ gender + SectionID + raisedhands, family = binomial(link = 'logit'),
method = 'glm')
summary(educ_lmodel)
educ_pred <- predict(educ_lmodel, newdata = educ_test)
head(educ_pred)
educ_prob <- predict(educ_lmodel, newdata = educ_test, type = 'prob')
head(educ_prob)
confusionMatrix(data = educ_pred, reference = educ_test$y, positive ="L" )
educ_test_set <- data.frame(H = educ_prob$H,
L = educ_prob$L,
pred = educ_pred,
obs = educ_test$y)
glimpse(educ_test_set)
levs <- levels(educ_test_set$obs)
twoClassSummary(educ_test_set, lev = levs) # don't work with tibble
prSummary(educ_test_set, lev = levs) # нужен пакет MLmetrics
ggplot(educ_test_set, aes(d = obs, m = L)) +
geom_roc(n.cuts = 0) +
labs(title = 'Кривая ROC',
x = 'False positive ratio = FP / (FP + TN)',
y = 'True positive ratio = TP / (TP + FN)')
educ_test_set <- mutate(educ_test_set, gender = educ_test$gender)
ggplot(educ_test_set, aes(d = obs, m = L, color = gender)) +
geom_roc(n.cuts = 0) +
labs(title = 'Кривые ROC в зависимости от пола',
x = 'False positive ratio = FP / (FP + TN)',
y = 'True positive ratio = TP / (TP + FN)',
color = 'Пол')
ranger_import <- varImp(ranger_model)
ranger_model <- train(y ~ . - Class, data = educ_test,
method = "ranger",
na.action = na.omit,
importance = 'impurity',
tuneLength = 4)
ranger_model <- train(y ~ ., data = educ_test,
method = 'ranger',
na.action = na.omit,
importance = 'impurity')
ranger_model
plot(ranger_model,
xlab = 'Количество случайно отбираемых регрессоров',
ylab = 'Точность (бутстрэп оценка)',
main = 'Зависимость точности от настроек дерева',
auto.key = list(title = 'Алгоритм разбиения ветки', cex.title = 1))
ranger_model <- train(y ~ ., data = educ_train,
method = 'ranger',
na.action = na.omit,
importance = 'impurity')
ranger_model
plot(ranger_model,
xlab = 'Количество случайно отбираемых регрессоров',
ylab = 'Точность (бутстрэп оценка)',
main = 'Зависимость точности от настроек дерева',
auto.key = list(title = 'Алгоритм разбиения ветки', cex.title = 1))
ranger_model <- train(y ~ ., data = educ_train,
method = 'ranger',
na.action = na.omit,
importance = 'impurity')
ranger_model
set.seed(777)
ranger_model <- train(y ~ ., data = educ_train,
method = 'ranger',
na.action = na.omit,
importance = 'impurity')
ranger_model
plot(ranger_model,
xlab = 'Количество случайно отбираемых регрессоров',
ylab = 'Точность (бутстрэп оценка)',
main = 'Зависимость точности от настроек дерева',
auto.key = list(title = 'Алгоритм разбиения ветки', cex.title = 1))
ranger_model$finalModel
ranger_import <- varImp(ranger_model)
ranger_import
plot(ranger_import,
main = 'Важность переменных случайного леса',
xlab = 'Среднее падение индекса Джини')
educ_ranger <- mutate(educ_test,
yhat = predict(ranger_model, educ_test, na.action = na.pass))
confusionMatrix(educ_ranger$yhat, educ_ranger$y)
modelLookup(model = 'ranger')
ranger_model <- train(y ~ . - Class, data = educ_test,
method = "ranger",
na.action = na.omit,
importance = 'impurity',
tuneLength = 4)
ranger_model <- train(y ~ ., data = educ_test,
method = "ranger",
na.action = na.omit,
importance = 'impurity',
tuneLength = 4)
grid <- expand.grid(mtry = c(5, 10), min.node.size = c(1, 5), splitrule = 'gini')
ranger_model <- train(y ~ . - Class, data = educ_test,
tuneGrid = grid, method = "ranger", na.action = na.omit)
ranger_model <- train(y ~ ., data = educ_test,
tuneGrid = grid, method = "ranger", na.action = na.omit)
ranger_model
trctrl <- trainControl(method = 'cv', number = 5)
set.seed(777)
educ_knn_fit <- train(y ~. -Class, data = educ_train, method = 'knn',
trControl = trctrl,
preProcess = c('center', 'scale'))
educ_knn_fit <- train(y ~., data = educ_train, method = 'knn',
trControl = trctrl,
preProcess = c('center', 'scale'))
educ_knn_fit <- train(y ~ ., data = educ_train, method = 'knn',
trControl = trctrl,
preProcess = c('center', 'scale'))
educ_knn_fit
